{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Amczgrxvpfcl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df=pd.read_csv('/content/diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jjcwhaHU52oz"
      },
      "outputs": [],
      "source": [
        "X=df.iloc[:,:-1].values\n",
        "y=df.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wY4qN83ukLY"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data preparation complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaJGpinUutEJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer with He Normal initialization\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units_input', min_value=16, max_value=128, step=16),\n",
        "        activation=hp.Choice('activation_input', values=['relu', 'leaky_relu', 'elu', 'selu', 'gelu', 'swish']),\n",
        "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "        input_dim=X_train.shape[1]\n",
        "    ))\n",
        "\n",
        "    # Hidden layers with He Normal initialization\n",
        "    for i in range(hp.Int('num_hidden_layers', 1, 3)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=16, max_value=128, step=16),\n",
        "            activation=hp.Choice(f'activation_{i}', values=['relu', 'leaky_relu', 'PReLU', 'selu',]),\n",
        "            kernel_initializer=tf.keras.initializers.HeNormal()\n",
        "        ))\n",
        "        model.add(Dropout(hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer with linear activation\n",
        "    model.add(Dense(\n",
        "        1,\n",
        "        activation='linear',\n",
        "        kernel_initializer=tf.keras.initializers.HeNormal()\n",
        "    ))\n",
        "\n",
        "    # Optimizer tuning\n",
        "    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4]))\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4]))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA2EdSecv78K"
      },
      "source": [
        "# Random search or hyperband"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jmmHwFLv4wj"
      },
      "outputs": [],
      "source": [
        "# Instantiate a Keras Tuner instance\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_mae',  # Tuning for validation mean absolute error\n",
        "    max_trials=10,  # Number of hyperparameter trials\n",
        "    executions_per_trial=1,  # Number of model executions per trial\n",
        "    directory='my_tuning_dir',  # Directory for saving tuning results\n",
        "    project_name='regression_tuning'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Get the best model\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the best model on the full dataset\n",
        "history = best_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WieY2UKuz6H"
      },
      "outputs": [],
      "source": [
        "# Step 3: Hyperparameter Search with Keras Tuner\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_mae',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='tuner_dir',\n",
        "    project_name='regression_with_optimizer_tuning'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(best_hps.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzbljCSvu2QP"
      },
      "outputs": [],
      "source": [
        "# Step 4: Train the Best Model\n",
        "\n",
        "# Rebuild the model using the best hyperparameters\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Dense(\n",
        "    units=int(best_hps.get('units_input')),\n",
        "    activation=best_hps.get('activation_input'),\n",
        "    input_dim=X_train.shape[1]\n",
        "))\n",
        "\n",
        "# Hidden layers\n",
        "for i in range(int(best_hps.get('num_hidden_layers'))):\n",
        "    model.add(Dense(\n",
        "        units=int(best_hps.get(f'units_{i}')),\n",
        "        activation=best_hps.get(f'activation_{i}')\n",
        "    ))\n",
        "    model.add(Dropout(best_hps.get(f'dropout_{i}')))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Optimizer\n",
        "if best_hps.get('optimizer') == 'adam':\n",
        "    opt = Adam(learning_rate=best_hps.get('learning_rate'))\n",
        "elif best_hps.get('optimizer') == 'rmsprop':\n",
        "    opt = RMSprop(learning_rate=best_hps.get('learning_rate'))\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "777jTnCtu5PN"
      },
      "outputs": [],
      "source": [
        "# Step 5: Evaluate and Save the Model\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('final_regression_model.h5')\n",
        "print(\"Model saved as 'final_regression_model.h5'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhP4cn2wvBq-"
      },
      "outputs": [],
      "source": [
        "# Step 2: Generate Predictions\n",
        "\n",
        "# Predictions for training and testing datasets\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Combine data for whole dataset analysis\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "print(\"Predictions generated for all datasets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8kgG594vFoG"
      },
      "outputs": [],
      "source": [
        "# Step 3: Calculate Metrics\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    max_error = np.max(np.abs(y_true - y_pred))\n",
        "    min_error = np.min(np.abs(y_true - y_pred))\n",
        "    return r2, rmse, mae, mape, max_error, min_error\n",
        "\n",
        "# Calculate metrics for training, testing, and whole dataset\n",
        "metrics_train = calculate_metrics(y_train, y_train_pred)\n",
        "metrics_test = calculate_metrics(y_test, y_test_pred)\n",
        "metrics_whole = calculate_metrics(y, y_pred)\n",
        "\n",
        "# Store metrics in a DataFrame for easy saving and visualization\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Dataset': ['Training', 'Testing', 'Whole'],\n",
        "    'R2': [metrics_train[0], metrics_test[0], metrics_whole[0]],\n",
        "    'RMSE': [metrics_train[1], metrics_test[1], metrics_whole[1]],\n",
        "    'MAE': [metrics_train[2], metrics_test[2], metrics_whole[2]],\n",
        "    'MAPE': [metrics_train[3], metrics_test[3], metrics_whole[3]],\n",
        "    'Max Error': [metrics_train[4], metrics_test[4], metrics_whole[4]],\n",
        "    'Min Error': [metrics_train[5], metrics_test[5], metrics_whole[5]],\n",
        "})\n",
        "\n",
        "print(\"Metrics calculated:\")\n",
        "print(metrics_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_-CzUGdvIM9"
      },
      "outputs": [],
      "source": [
        "# Step 4: Save Results and Predictions\n",
        "\n",
        "import os\n",
        "\n",
        "# Create an output directory if it doesn't exist\n",
        "output_dir = \"./output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save metrics\n",
        "metrics_df.to_csv(os.path.join(output_dir, 'evaluation_metrics.csv'), index=False)\n",
        "\n",
        "# Save predictions and actual data\n",
        "np.save(os.path.join(output_dir, 'y_train'), y_train)\n",
        "np.save(os.path.join(output_dir, 'y_train_pred'), y_train_pred)\n",
        "np.save(os.path.join(output_dir, 'y_test'), y_test)\n",
        "np.save(os.path.join(output_dir, 'y_test_pred'), y_test_pred)\n",
        "np.save(os.path.join(output_dir, 'X'), X)\n",
        "np.save(os.path.join(output_dir, 'y_pred'), y_pred)\n",
        "\n",
        "print(f\"Results saved in '{output_dir}' directory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApSuT1czvKq4"
      },
      "outputs": [],
      "source": [
        "# Step 5: Visualize Metrics (Optional)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot metrics\n",
        "metrics_df.set_index('Dataset')[['R2', 'RMSE', 'MAE', 'MAPE']].plot(\n",
        "    kind='bar', figsize=(10, 6), color=['blue', 'orange', 'green', 'red']\n",
        ")\n",
        "plt.title('Model Evaluation Metrics')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.xlabel('Dataset')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Metrics')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'metrics_plot.png'), dpi=2000)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBv7ObAFvScI"
      },
      "outputs": [],
      "source": [
        "# Step 6: Visualize Training History\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.title('Model Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
